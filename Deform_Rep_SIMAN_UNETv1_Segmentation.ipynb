{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ae9d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fast grouped deform_conv2d available: False\n",
      "[0020/200] loss=0.1100  dice=0.9489\n",
      "[0040/200] loss=0.0255  dice=0.9917\n",
      "[0060/200] loss=0.0159  dice=0.9944\n",
      "[0080/200] loss=0.0121  dice=0.9956\n",
      "[0100/200] loss=0.0088  dice=0.9973\n",
      "[0120/200] loss=0.0081  dice=0.9970\n",
      "[0140/200] loss=0.0087  dice=0.9960\n",
      "[0160/200] loss=0.0114  dice=0.9934\n",
      "[0180/200] loss=0.0072  dice=0.9964\n",
      "[0200/200] loss=0.0069  dice=0.9964\n",
      "Output shape: torch.Size([2, 1, 128, 128])  | Pred mask unique values: tensor([0., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lightweight U-Net for segmentation with:\n",
    "- RepConv blocks (encoder/decoder/head)\n",
    "- SimAM attention on skip-add fusion\n",
    "- Bottleneck: SPPF-like (1x1 -> Depthwise DCNv2 -> 1x1)\n",
    "- Cheap DW+PW offset/mask heads for deformable conv\n",
    "\n",
    "Includes a minimal synthetic segmentation example (circles).\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import inspect\n",
    "import argparse\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =========================\n",
    "# Optional: torchvision deform_conv2d\n",
    "# =========================\n",
    "try:\n",
    "    import torchvision.ops as tvops\n",
    "    _HAS_TV = True\n",
    "except Exception:\n",
    "    tvops = None\n",
    "    _HAS_TV = False\n",
    "\n",
    "def _supports_groups_in_deform() -> bool:\n",
    "    if not _HAS_TV: \n",
    "        return False\n",
    "    try:\n",
    "        sig = inspect.signature(tvops.deform_conv2d)\n",
    "        return \"groups\" in sig.parameters\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "_HAS_GROUPS = _supports_groups_in_deform()\n",
    "\n",
    "# =========================\n",
    "# SimAM: parameter-free attention\n",
    "# =========================\n",
    "class SimAM(nn.Module):\n",
    "    def __init__(self, lambda_val: float = 1e-4):\n",
    "        super().__init__()\n",
    "        self.lambda_val = lambda_val\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        b, c, h, w = x.shape\n",
    "        n = h * w - 1\n",
    "        mean = x.mean(dim=(2, 3), keepdim=True)\n",
    "        var = ((x - mean) ** 2).sum(dim=(2, 3), keepdim=True) / (n + 1e-6)\n",
    "        e = (x - mean) ** 2 / (4 * (var + self.lambda_val)) + 0.5\n",
    "        w = torch.sigmoid(e)\n",
    "        return x * w\n",
    "\n",
    "# =========================\n",
    "# RepConv (train-time multi-branch, deploy single 3x3)\n",
    "# =========================\n",
    "class RepConv(nn.Module):\n",
    "    def __init__(self, c_in, c_out, s=1, deploy=False, act=True):\n",
    "        super().__init__()\n",
    "        self.deploy = deploy\n",
    "        self.stride = s\n",
    "        self.act = nn.ReLU6(inplace=True) if act else nn.Identity()\n",
    "\n",
    "        if deploy:\n",
    "            self.rbr_reparam = nn.Conv2d(c_in, c_out, 3, s, 1, bias=True)\n",
    "        else:\n",
    "            self.rbr_identity = nn.BatchNorm2d(c_in) if (c_out == c_in and s == 1) else None\n",
    "            self.rbr_dense = nn.Sequential(\n",
    "                nn.Conv2d(c_in, c_out, 3, s, 1, bias=False),\n",
    "                nn.BatchNorm2d(c_out),\n",
    "            )\n",
    "            self.rbr_1x1 = nn.Sequential(\n",
    "                nn.Conv2d(c_in, c_out, 1, s, 0, bias=False),\n",
    "                nn.BatchNorm2d(c_out),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if hasattr(self, \"rbr_reparam\"):\n",
    "            out = self.rbr_reparam(x)\n",
    "        else:\n",
    "            id_out = self.rbr_identity(x) if self.rbr_identity is not None else 0\n",
    "            out = self.rbr_dense(x) + self.rbr_1x1(x) + id_out\n",
    "        return self.act(out)\n",
    "\n",
    "    def get_equivalent_kernel_bias(self):\n",
    "        \"\"\"Fuse 3x3, 1x1 and (optional) identity branches into one 3x3 Conv2d kernel+bias.\"\"\"\n",
    "        if hasattr(self, \"rbr_reparam\"):\n",
    "            return self.rbr_reparam.weight, self.rbr_reparam.bias\n",
    "\n",
    "        # Helper to fuse conv+bn\n",
    "        def fuse_conv_bn(conv, bn):\n",
    "            w = conv.weight\n",
    "            if conv.kernel_size == (1, 1):\n",
    "                # pad to 3x3\n",
    "                w = F.pad(w, [1, 1, 1, 1])\n",
    "            gamma = bn.weight\n",
    "            beta = bn.bias\n",
    "            mean = bn.running_mean\n",
    "            var = bn.running_var\n",
    "            eps = bn.eps\n",
    "            std = torch.sqrt(var + eps)\n",
    "            w_fused = w * (gamma / std).reshape(-1, 1, 1, 1)\n",
    "            b_fused = beta - mean * gamma / std\n",
    "            return w_fused, b_fused\n",
    "\n",
    "        w3, b3 = fuse_conv_bn(self.rbr_dense[0], self.rbr_dense[1])\n",
    "        w1, b1 = fuse_conv_bn(self.rbr_1x1[0], self.rbr_1x1[1])\n",
    "\n",
    "        if self.rbr_identity is not None:\n",
    "            # Identity BN as 3x3 kernel (delta kernel)\n",
    "            id_ch = self.rbr_identity.num_features\n",
    "            id_kernel = torch.zeros((id_ch, id_ch, 3, 3), device=w3.device, dtype=w3.dtype)\n",
    "            for i in range(id_ch):\n",
    "                id_kernel[i, i, 1, 1] = 1.0\n",
    "            gamma = self.rbr_identity.weight\n",
    "            beta = self.rbr_identity.bias\n",
    "            mean = self.rbr_identity.running_mean\n",
    "            var = self.rbr_identity.running_var\n",
    "            eps = self.rbr_identity.eps\n",
    "            std = torch.sqrt(var + eps)\n",
    "            w_id = id_kernel * (gamma / std).reshape(-1, 1, 1, 1)\n",
    "            b_id = beta - mean * gamma / std\n",
    "        else:\n",
    "            w_id = torch.zeros_like(w3)\n",
    "            b_id = torch.zeros_like(b3)\n",
    "\n",
    "        w = w3 + w1 + w_id\n",
    "        b = b3 + b1 + b_id\n",
    "        return w, b\n",
    "\n",
    "    def fuse_reparam(self):\n",
    "        if hasattr(self, \"rbr_reparam\"):\n",
    "            return\n",
    "        W, B = self.get_equivalent_kernel_bias()\n",
    "        self.rbr_reparam = nn.Conv2d(\n",
    "            in_channels=self.rbr_dense[0].in_channels,\n",
    "            out_channels=self.rbr_dense[0].out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=self.stride,\n",
    "            padding=1,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.rbr_reparam.weight.data = W\n",
    "        self.rbr_reparam.bias.data = B\n",
    "        # Delete old branches\n",
    "        del self.rbr_dense, self.rbr_1x1\n",
    "        if self.rbr_identity is not None:\n",
    "            del self.rbr_identity\n",
    "\n",
    "# =========================\n",
    "# Cheap DW+PW block for offset/modulator\n",
    "# =========================\n",
    "class CheapOffsetConv(nn.Module):\n",
    "    \"\"\"Depthwise 3x3 + BN + ReLU6 + Pointwise 1x1 (DW-PW).\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, k=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=k, stride=stride,\n",
    "                      padding=padding, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=True),\n",
    "        )\n",
    "        # init last conv to zero: start at \"no deformation\"\n",
    "        nn.init.constant_(self.block[-1].weight, 0.)\n",
    "        nn.init.constant_(self.block[-1].bias, 0.)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "# =========================\n",
    "# Depthwise Deformable Conv2d (DW-DCNv2)\n",
    "# =========================\n",
    "class DeformableDWConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Depthwise deformable conv:\n",
    "      - offset head: CheapOffsetConv -> 2*k*k\n",
    "      - mask head:   CheapOffsetConv -> k*k (scaled to [0,2])\n",
    "      - weight: [C, 1, kH, kW], groups=C\n",
    "    Fast path uses torchvision.deform_conv2d with groups.\n",
    "    Fallback: per-channel loop (slower, but correct).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False):\n",
    "        super().__init__()\n",
    "        k = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n",
    "        self.k = k\n",
    "        self.stride = stride if isinstance(stride, tuple) else (stride, stride)\n",
    "        self.padding = padding if isinstance(padding, tuple) else (padding, padding)\n",
    "        self.dilation = dilation\n",
    "        self.in_channels = in_channels\n",
    "        self.bias_flag = bias\n",
    "        ks2 = k[0] * k[1]\n",
    "\n",
    "        self.offset_conv = CheapOffsetConv(in_channels, 2 * ks2, k=3, stride=self.stride, padding=1)\n",
    "        self.modulator_conv = CheapOffsetConv(in_channels, ks2, k=3, stride=self.stride, padding=1)\n",
    "\n",
    "        self.weight = nn.Parameter(torch.empty(in_channels, 1, *k))\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n",
    "        self.bias = nn.Parameter(torch.zeros(in_channels)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not _HAS_TV:\n",
    "            raise RuntimeError(\"torchvision.ops.deform_conv2d is required for this module.\")\n",
    "\n",
    "        offset = self.offset_conv(x)                      # [B, 2*k*k, H', W']\n",
    "        mask = 2.0 * torch.sigmoid(self.modulator_conv(x))  # [B, k*k, H', W']\n",
    "\n",
    "        if _HAS_GROUPS:\n",
    "            return tvops.deform_conv2d(\n",
    "                input=x,\n",
    "                offset=offset,\n",
    "                weight=self.weight,\n",
    "                bias=self.bias if self.bias_flag else None,\n",
    "                stride=self.stride,\n",
    "                padding=self.padding,\n",
    "                dilation=self.dilation,\n",
    "                mask=mask,\n",
    "                groups=self.in_channels,\n",
    "            )\n",
    "        else:\n",
    "            # Per-channel fallback\n",
    "            outs = []\n",
    "            for c in range(self.in_channels):\n",
    "                xc = x[:, c:c+1]\n",
    "                wc = self.weight[c:c+1]\n",
    "                bc = self.bias[c:c+1] if self.bias is not None else None\n",
    "                yc = tvops.deform_conv2d(\n",
    "                    xc, offset, wc, bias=bc,\n",
    "                    stride=self.stride, padding=self.padding,\n",
    "                    dilation=self.dilation, mask=mask\n",
    "                )\n",
    "                outs.append(yc)\n",
    "            return torch.cat(outs, dim=1)\n",
    "\n",
    "# =========================\n",
    "# SPPF-like bottleneck (1x1 -> DW-DCNv2 -> 1x1)\n",
    "# =========================\n",
    "class SPPF_DW_DCN(nn.Module):\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.reduce = nn.Sequential(\n",
    "            nn.Conv2d(c, c, 1, bias=False),\n",
    "            nn.BatchNorm2d(c),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "        self.dw_dcn = DeformableDWConv2d(c, kernel_size=3, stride=1, padding=1, dilation=1, bias=True)\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.Conv2d(c, c, 1, bias=False),\n",
    "            nn.BatchNorm2d(c),\n",
    "            nn.ReLU6(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.reduce(x)\n",
    "        x = self.dw_dcn(x)\n",
    "        x = self.expand(x)\n",
    "        return x\n",
    "\n",
    "# =========================\n",
    "# U-Net building blocks\n",
    "# =========================\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            RepConv(c_in, c_out, s=2),  # downsample\n",
    "            RepConv(c_out, c_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, c_in, c_skip, c_out, use_simam=True):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c_out)\n",
    "        self.skip_proj = nn.Conv2d(c_skip, c_out, 1, bias=False)\n",
    "        self.skip_bn = nn.BatchNorm2d(c_out)\n",
    "        self.attn = SimAM() if use_simam else nn.Identity()\n",
    "        self.block = RepConv(c_out, c_out)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = F.interpolate(x, size=skip.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        x = F.relu6(self.bn(self.proj(x)), inplace=True)\n",
    "        s = F.relu6(self.skip_bn(self.skip_proj(skip)), inplace=True)\n",
    "        x = self.attn(x + s)  # add-fusion + SimAM\n",
    "        return self.block(x)\n",
    "\n",
    "# =========================\n",
    "# The Lightweight U-Net\n",
    "# =========================\n",
    "class UNetLite_Rep_SimAM_DWDCN(nn.Module):\n",
    "    def __init__(self, in_ch=3, n_classes=1, width=1.0, use_simam=True):\n",
    "        super().__init__()\n",
    "        def C(c): return max(8, int(c * width))\n",
    "\n",
    "        # Stem\n",
    "        self.stem = nn.Sequential(\n",
    "            RepConv(in_ch, C(16)),\n",
    "            RepConv(C(16), C(16)),\n",
    "        )\n",
    "\n",
    "        # Encoder\n",
    "        self.d1 = Down(C(16), C(32))\n",
    "        self.d2 = Down(C(32), C(64))\n",
    "        self.d3 = Down(C(64), C(128))\n",
    "        self.d4 = Down(C(128), C(192))\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bot = SPPF_DW_DCN(C(192))\n",
    "\n",
    "        # Decoder\n",
    "        self.u4 = Up(C(192), C(128), C(96), use_simam)\n",
    "        self.u3 = Up(C(96),  C(64),  C(64), use_simam)\n",
    "        self.u2 = Up(C(64),  C(32),  C(48), use_simam)\n",
    "        self.u1 = Up(C(48),  C(16),  C(32), use_simam)\n",
    "\n",
    "        # Head\n",
    "        self.head = nn.Sequential(\n",
    "            RepConv(C(32), C(32)),\n",
    "            nn.Conv2d(C(32), n_classes, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        s0 = self.stem(x)       # C16\n",
    "        s1 = self.d1(s0)        # C32\n",
    "        s2 = self.d2(s1)        # C64\n",
    "        s3 = self.d3(s2)        # C128\n",
    "        s4 = self.d4(s3)        # C192\n",
    "        b  = self.bot(s4)\n",
    "        x  = self.u4(b, s3)\n",
    "        x  = self.u3(x, s2)\n",
    "        x  = self.u2(x, s1)\n",
    "        x  = self.u1(x, s0)\n",
    "        return self.head(x)\n",
    "\n",
    "    def fuse_reparam(self):\n",
    "        \"\"\"Fuse RepConv branches for deployment.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, RepConv):\n",
    "                m.fuse_reparam()\n",
    "\n",
    "# =========================\n",
    "# Toy dataset: synthetic circles\n",
    "# =========================\n",
    "def make_circles_batch(B: int, H: int, W: int, device=\"cpu\") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Generates a batch of simple images with filled circles and corresponding masks.\n",
    "    Images: 3-channel, masks: 1-channel (0/1).\n",
    "    \"\"\"\n",
    "    yy, xx = torch.meshgrid(torch.linspace(-1, 1, H, device=device),\n",
    "                            torch.linspace(-1, 1, W, device=device), indexing=\"ij\")\n",
    "    imgs, masks = [], []\n",
    "    for _ in range(B):\n",
    "        cx = torch.empty(1, device=device).uniform_(-0.4, 0.4).item()\n",
    "        cy = torch.empty(1, device=device).uniform_(-0.4, 0.4).item()\n",
    "        r  = torch.empty(1, device=device).uniform_(0.15, 0.35).item()\n",
    "        circle = ((xx - cx)**2 + (yy - cy)**2) <= (r**2)\n",
    "        mask = circle.float().unsqueeze(0)  # [1,H,W]\n",
    "        # Simple texture: mask + noise\n",
    "        noise = 0.2 * torch.randn(1, H, W, device=device)\n",
    "        img = mask * 0.8 + (1 - mask) * 0.2 + noise\n",
    "        img = img.clamp(0, 1).repeat(3, 1, 1)  # 3-channel\n",
    "        imgs.append(img)\n",
    "        masks.append(mask)\n",
    "    return torch.stack(imgs, 0), torch.stack(masks, 0)\n",
    "\n",
    "# =========================\n",
    "# Loss: BCE + Soft Dice\n",
    "# =========================\n",
    "def dice_loss(logits, targets, eps=1e-6):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    dims = (2, 3)\n",
    "    num = 2 * (probs * targets).sum(dim=dims) + eps\n",
    "    den = (probs.pow(2) + targets.pow(2)).sum(dim=dims) + eps\n",
    "    return 1 - (num / den).mean()\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return self.bce(logits, targets) + dice_loss(logits, targets)\n",
    "\n",
    "# =========================\n",
    "# Example training loop\n",
    "# =========================\n",
    "def demo_train(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "\n",
    "    model = UNetLite_Rep_SimAM_DWDCN(in_ch=3, n_classes=1, width=args.width).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    criterion = BCEDiceLoss()\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Fast grouped deform_conv2d available: {_HAS_GROUPS}\")\n",
    "\n",
    "    model.train()\n",
    "    for it in range(args.iters):\n",
    "        imgs, masks = make_circles_batch(args.batch_size, args.size, args.size, device=device)\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, masks)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (it + 1) % max(1, args.iters // 10) == 0:\n",
    "            with torch.no_grad():\n",
    "                dice = 1 - dice_loss(logits, masks).item()\n",
    "            print(f\"[{it+1:04d}/{args.iters}] loss={loss.item():.4f}  dice={dice:.4f}\")\n",
    "\n",
    "    # Optionally fuse RepConv branches for deployment\n",
    "    if args.fuse:\n",
    "        model.fuse_reparam()\n",
    "        print(\"RepConv branches fused for deployment.\")\n",
    "\n",
    "    # Quick sanity check on a batch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        imgs, masks = make_circles_batch(2, args.size, args.size, device=device)\n",
    "        logits = model(imgs)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        print(\"Output shape:\", logits.shape, \" | Pred mask unique values:\", preds.unique())\n",
    "\n",
    "    return model\n",
    "\n",
    "# =========================\n",
    "# CLI\n",
    "# =========================\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--size\", type=int, default=128, help=\"input H=W\")\n",
    "    p.add_argument(\"--batch_size\", type=int, default=4)\n",
    "    p.add_argument(\"--iters\", type=int, default=200)\n",
    "    p.add_argument(\"--lr\", type=float, default=3e-3)\n",
    "    p.add_argument(\"--width\", type=float, default=0.75, help=\"global width multiplier\")\n",
    "    p.add_argument(\"--cpu\", action=\"store_true\", help=\"force CPU\")\n",
    "    p.add_argument(\"--fuse\", action=\"store_true\", help=\"fuse RepConv for deploy after training\")\n",
    "    return p.parse_args([])  # change to [] for notebook, or remove to parse CLI\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    demo_train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f39f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Params]  Proposed: 0.71 M | Vanilla: 31.04 M\n",
      "[Latency] Proposed: 26.70 ms | Vanilla: 20.23 ms  (512x512, bs=1)\n",
      "[Complexity] Proposed: MACs=7.94 G | GFLOPs≈15.87\n",
      "[Complexity] Vanilla : MACs=193.28 G | GFLOPs≈386.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shuja\\AppData\\Local\\Temp\\ipykernel_23076\\1436503208.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def count_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_latency(model: nn.Module, H=512, W=512, *, runs=30, device='cuda') -> float:\n",
    "    model.eval().to(device)\n",
    "    model.to(memory_format=torch.channels_last)\n",
    "    x = torch.randn(1, 3, H, W, device=device).to(memory_format=torch.channels_last)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(8):\n",
    "        _ = model(x)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.time()\n",
    "    for _ in range(runs):\n",
    "        _ = model(x)\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    return (time.time() - t0) / runs\n",
    "\n",
    "def try_profile_macs_flops(model: nn.Module, H=512, W=512, device='cuda'):\n",
    "    \"\"\"\n",
    "    Returns (params_M, GMACs, GFLOPs) if ptflops or thop is available.\n",
    "    If neither available, returns (params_M, None, None).\n",
    "    \"\"\"\n",
    "    params_m = count_params(model) / 1e6\n",
    "    model.eval().to(device).to(memory_format=torch.channels_last)\n",
    "    x = torch.randn(1, 3, H, W, device=device).to(memory_format=torch.channels_last)\n",
    "\n",
    "    # Prefer ptflops on Python 3.12\n",
    "    try:\n",
    "        from ptflops import get_model_complexity_info\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            macs, params = get_model_complexity_info(\n",
    "                model, (3, H, W), as_strings=False, print_per_layer_stat=False, verbose=False\n",
    "            )\n",
    "        gmacs = macs / 1e9\n",
    "        gflops = 2.0 * gmacs  # (multiply + add) convention\n",
    "        return params_m, gmacs, gflops\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback to thop if present\n",
    "    try:\n",
    "        from thop import profile\n",
    "        macs, _ = profile(model, inputs=(x,), verbose=False)\n",
    "        gmacs = macs / 1e9\n",
    "        gflops = 2.0 * gmacs\n",
    "        return params_m, gmacs, gflops\n",
    "    except Exception:\n",
    "        return params_m, None, None\n",
    "\n",
    "# =========================\n",
    "# Vanilla UNet (fixed decoder channel sizes)\n",
    "# =========================\n",
    "def conv3x3(ci, co): return nn.Conv2d(ci, co, 3, padding=1, bias=False)\n",
    "def bn(c): return nn.BatchNorm2d(c)\n",
    "def relu(): return nn.ReLU(inplace=True)\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, ci, co):\n",
    "        super().__init__()\n",
    "        self.m = nn.Sequential(\n",
    "            conv3x3(ci, co), bn(co), relu(),\n",
    "            conv3x3(co, co), bn(co), relu()\n",
    "        )\n",
    "    def forward(self, x): return self.m(x)\n",
    "\n",
    "class VanillaUNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, n_classes=1, base=64):\n",
    "        super().__init__()\n",
    "        C0, C1, C2, C3, C4 = base, base*2, base*4, base*8, base*16\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_ch, C0); self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(C0, C1);    self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(C1, C2);    self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = DoubleConv(C2, C3);    self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bott = DoubleConv(C3, C4)\n",
    "\n",
    "        # Decoder (note: concat doubles channels → 2*C? → C?)\n",
    "        self.up4  = nn.ConvTranspose2d(C4, C3, 2, 2)\n",
    "        self.dec4 = DoubleConv(C3 + C3, C3)\n",
    "\n",
    "        self.up3  = nn.ConvTranspose2d(C3, C2, 2, 2)\n",
    "        self.dec3 = DoubleConv(C2 + C2, C2)\n",
    "\n",
    "        self.up2  = nn.ConvTranspose2d(C2, C1, 2, 2)\n",
    "        self.dec2 = DoubleConv(C1 + C1, C1)\n",
    "\n",
    "        self.up1  = nn.ConvTranspose2d(C1, C0, 2, 2)\n",
    "        self.dec1 = DoubleConv(C0 + C0, C0)\n",
    "\n",
    "        self.head = nn.Conv2d(C0, n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        e4 = self.enc4(self.pool3(e3))\n",
    "        b  = self.bott(self.pool4(e4))\n",
    "\n",
    "        d4 = self.up4(b); d4 = torch.cat([d4, e4], dim=1); d4 = self.dec4(d4)\n",
    "        d3 = self.up3(d4); d3 = torch.cat([d3, e3], dim=1); d3 = self.dec3(d3)\n",
    "        d2 = self.up2(d3); d2 = torch.cat([d2, e2], dim=1); d2 = self.dec2(d2)\n",
    "        d1 = self.up1(d2); d1 = torch.cat([d1, e1], dim=1); d1 = self.dec1(d1)\n",
    "        return self.head(d1)\n",
    "\n",
    "# =========================\n",
    "# Your proposed model\n",
    "# =========================\n",
    "# Make sure this class is already defined in your session or import it:\n",
    "# from your_file import UNetLite_Rep_SimAM_DWDCN\n",
    "\n",
    "# =========================\n",
    "# Run the comparison\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Instantiate models\n",
    "    proposed = UNetLite_Rep_SimAM_DWDCN(in_ch=3, n_classes=1, width=0.75)\n",
    "    vanilla  = VanillaUNet(in_ch=3, n_classes=1, base=64)  # classic UNet capacity\n",
    "\n",
    "    # Params\n",
    "    p_params_m = count_params(proposed) / 1e6\n",
    "    v_params_m = count_params(vanilla)  / 1e6\n",
    "\n",
    "    # Latency @ 512x512\n",
    "    p_lat = benchmark_latency(proposed, 512, 512, runs=30, device=device)\n",
    "    v_lat = benchmark_latency(vanilla,  512, 512, runs=30, device=device)\n",
    "\n",
    "    print(f\"[Params]  Proposed: {p_params_m:.2f} M | Vanilla: {v_params_m:.2f} M\")\n",
    "    print(f\"[Latency] Proposed: {p_lat*1000:.2f} ms | Vanilla: {v_lat*1000:.2f} ms  (512x512, bs=1)\")\n",
    "\n",
    "    # MACs / GFLOPs if profiler available\n",
    "    p_params_m2, p_gmacs, p_gflops = try_profile_macs_flops(proposed, 512, 512, device)\n",
    "    v_params_m2, v_gmacs, v_gflops = try_profile_macs_flops(vanilla,  512, 512, device)\n",
    "\n",
    "    if p_gmacs is not None and v_gmacs is not None:\n",
    "        print(f\"[Complexity] Proposed: MACs={p_gmacs:.2f} G | GFLOPs≈{p_gflops:.2f}\")\n",
    "        print(f\"[Complexity] Vanilla : MACs={v_gmacs:.2f} G | GFLOPs≈{v_gflops:.2f}\")\n",
    "    else:\n",
    "        print(\"[Complexity] Skipped MACs/GFLOPs (install ptflops or thop to enable).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
