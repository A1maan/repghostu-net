{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0cb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: torch.Size([1, 1, 256, 256])\n",
      "deploy out: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# repghost_unet.py\n",
    "# U-Net with RepGhost blocks (PyTorch >= 1.10)\n",
    "# Paper / repo (concept & fusion idea): RepGhost: A Hardware-Efficient Ghost Module via Re-parameterization\n",
    "# https://arxiv.org/abs/2211.06088  (module: add instead of concat; move ReLU; identity-BN branch; fuse for deploy)\n",
    "# https://github.com/ChengpengChen/RepGhost\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utils\n",
    "# -------------------------\n",
    "\n",
    "def _bn_to_scale_shift(bn: nn.BatchNorm2d):\n",
    "    \"\"\"Return per-channel scale and shift for folding BN into preceding linear op.\"\"\"\n",
    "    # y = gamma * (x - mean) / sqrt(var + eps) + beta  ==  scale * x + shift\n",
    "    gamma = bn.weight\n",
    "    beta = bn.bias\n",
    "    mean = bn.running_mean\n",
    "    var = bn.running_var\n",
    "    eps = bn.eps\n",
    "    scale = gamma / torch.sqrt(var + eps)\n",
    "    shift = beta - mean * scale\n",
    "    return scale, shift\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Squeeze-and-Excitation (optional)\n",
    "# -------------------------\n",
    "\n",
    "class SqueezeExcite(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        hidden = max(8, channels // reduction)\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(channels, hidden, 1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(hidden, channels, 1, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.fc(self.avg(x))\n",
    "        return x * w\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# RepGhost module (training-time)  -> convertible to a single DW conv (deploy)\n",
    "# Diagram matches Fig. 3(d-e) in the paper: depthwise conv branch + identity-BN branch, then ReLU.\n",
    "# We assume Cin == Cout inside the module (preceded/followed by 1x1 convs in the bottleneck).\n",
    "# -------------------------\n",
    "\n",
    "class RepGhostModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Training graph:\n",
    "        y = BN_dw(DW(x)) + BN_id(x)\n",
    "        y = ReLU(y)\n",
    "    Deploy graph (after convert_to_deploy):\n",
    "        y = DW_fused(x) + bias; ReLU(y)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int, ksize: int = 3, stride: int = 1, deploy: bool = False):\n",
    "        super().__init__()\n",
    "        padding = ksize // 2\n",
    "        self.channels = channels\n",
    "        self.stride = stride\n",
    "        self.ksize = ksize\n",
    "        self.deploy = deploy\n",
    "\n",
    "        if deploy:\n",
    "            # Single depthwise conv with bias (fused)\n",
    "            self.reparam = nn.Conv2d(channels, channels, ksize, stride, padding,\n",
    "                                     groups=channels, bias=True)\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "        else:\n",
    "            # Depthwise conv branch + BN\n",
    "            self.dw = nn.Conv2d(channels, channels, ksize, stride, padding,\n",
    "                                groups=channels, bias=False)\n",
    "            self.dw_bn = nn.BatchNorm2d(channels)\n",
    "\n",
    "            # Identity branch with BN (no spatial conv)\n",
    "            self.id_bn = nn.BatchNorm2d(channels)\n",
    "\n",
    "            self.act = nn.ReLU(inplace=True)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_to_deploy(self):\n",
    "        \"\"\"Fuse BN_dw(DW) + BN_id into a single DW conv with bias.\"\"\"\n",
    "        if self.deploy:\n",
    "            return\n",
    "\n",
    "        # 1) Fold BN into depthwise conv weights/bias\n",
    "        scale_dw, shift_dw = _bn_to_scale_shift(self.dw_bn)\n",
    "        # dw conv has no bias:\n",
    "        Wdw = self.dw.weight.clone()  # [C,1,kh,kw]\n",
    "        # scale each channel's kernel by its scale_dw\n",
    "        Wdw = Wdw * scale_dw.view(-1, 1, 1, 1)\n",
    "        bdw = shift_dw.clone()  # [C]\n",
    "\n",
    "        # 2) Convert BN_id(x) to a depthwise conv with an identity kernel\n",
    "        scale_id, shift_id = _bn_to_scale_shift(self.id_bn)\n",
    "        # Build an impulse (identity) kernel for depthwise conv\n",
    "        k = torch.zeros_like(Wdw)  # [C,1,kh,kw]\n",
    "        center = self.ksize // 2\n",
    "        k[:, 0, center, center] = scale_id\n",
    "\n",
    "        # 3) Sum both linear ops (same groups/channels), sum biases too\n",
    "        W_fused = Wdw + k\n",
    "        b_fused = bdw + shift_id\n",
    "\n",
    "        # 4) Create reparam conv and load weights\n",
    "        self.reparam = nn.Conv2d(self.channels, self.channels,\n",
    "                                 self.ksize, self.stride, self.ksize // 2,\n",
    "                                 groups=self.channels, bias=True)\n",
    "        self.reparam.weight.data.copy_(W_fused)\n",
    "        self.reparam.bias.data.copy_(b_fused)\n",
    "\n",
    "        # 5) Cleanup training branches\n",
    "        del self.dw, self.dw_bn, self.id_bn\n",
    "        self.deploy = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.deploy:\n",
    "            return self.act(self.reparam(x))\n",
    "        else:\n",
    "            y = self.dw_bn(self.dw(x))\n",
    "            y = y + self.id_bn(x)\n",
    "            return self.act(y)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# RepGhost Bottleneck-ish block:\n",
    "# 1x1 PW conv -> RepGhostModule -> (optional SE) -> 1x1 PW conv -> RepGhostModule\n",
    "# Keeps Cin/Cout flexible (U-Net-style). Residual optional when Cin==Cout.\n",
    "# -------------------------\n",
    "\n",
    "class RGBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_se=False, se_reduction=16, residual=False):\n",
    "        super().__init__()\n",
    "        mid = out_ch // 2  # \"thinner\" middle channels (Fig. 4b hint)\n",
    "        mid = max(8, mid)\n",
    "\n",
    "        self.proj1 = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, mid, 1, bias=False),\n",
    "            nn.BatchNorm2d(mid),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.rg1 = RepGhostModule(mid, ksize=3, stride=1)\n",
    "\n",
    "        self.se = SqueezeExcite(mid) if use_se else nn.Identity()\n",
    "\n",
    "        self.proj2 = nn.Sequential(\n",
    "            nn.Conv2d(mid, out_ch, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # second RG\n",
    "        self.rg2 = RepGhostModule(out_ch, ksize=3, stride=1)\n",
    "\n",
    "        self.residual = residual and (in_ch == out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.proj1(x)\n",
    "        x = self.rg1(x)\n",
    "        x = self.se(x)\n",
    "        x = self.proj2(x)\n",
    "        x = self.rg2(x)\n",
    "        if self.residual:\n",
    "            x = x + identity\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_to_deploy(self):\n",
    "        self.rg1.convert_to_deploy()\n",
    "        self.rg2.convert_to_deploy()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# U-Net with RepGhost blocks\n",
    "# -------------------------\n",
    "\n",
    "class DoubleRG(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_se=False):\n",
    "        super().__init__()\n",
    "        self.b1 = RGBlock(in_ch, out_ch, use_se=use_se, residual=False)\n",
    "        self.b2 = RGBlock(out_ch, out_ch, use_se=use_se, residual=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_to_deploy(self):\n",
    "        self.b1.convert_to_deploy()\n",
    "        self.b2.convert_to_deploy()\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_se=False):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.block = DoubleRG(in_ch, out_ch, use_se=use_se)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(self.pool(x))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_to_deploy(self):\n",
    "        self.block.convert_to_deploy()\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, use_se=False, bilinear=False):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            self.reduce = nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
    "            self.reduce = nn.Identity()\n",
    "        self.block = DoubleRG(out_ch * 2, out_ch, use_se=use_se)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        x = self.reduce(x)\n",
    "        # pad if needed (odd dims)\n",
    "        diffY = skip.size(-2) - x.size(-2)\n",
    "        diffX = skip.size(-1) - x.size(-1)\n",
    "        if diffY != 0 or diffX != 0:\n",
    "            x = F.pad(x, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.block(x)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_to_deploy(self):\n",
    "        self.block.convert_to_deploy()\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch, n_classes):\n",
    "        super().__init__\n",
    "        self.conv = nn.Conv2d(in_ch, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class RepGhostUNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1, base_ch=32, use_se=False, bilinear=False):\n",
    "        \"\"\"\n",
    "        base_ch=32 is a good lightweight start. Use 64 for larger models.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        c1, c2, c3, c4, c5 = base_ch, base_ch*2, base_ch*4, base_ch*8, base_ch*16\n",
    "\n",
    "        self.inc   = DoubleRG(n_channels, c1, use_se=use_se)\n",
    "        self.down1 = Down(c1, c2, use_se=use_se)\n",
    "        self.down2 = Down(c2, c3, use_se=use_se)\n",
    "        self.down3 = Down(c3, c4, use_se=use_se)\n",
    "        self.down4 = Down(c4, c5, use_se=use_se)\n",
    "\n",
    "        self.up1 = Up(c5, c4, use_se=use_se, bilinear=bilinear)\n",
    "        self.up2 = Up(c4, c3, use_se=use_se, bilinear=bilinear)\n",
    "        self.up3 = Up(c3, c2, use_se=use_se, bilinear=bilinear)\n",
    "        self.up4 = Up(c2, c1, use_se=use_se, bilinear=bilinear)\n",
    "\n",
    "        self.outc = nn.Conv2d(c1, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)     # [B, c1, H, W]\n",
    "        x2 = self.down1(x1)  # [B, c2, H/2, W/2]\n",
    "        x3 = self.down2(x2)  # [B, c3, H/4, W/4]\n",
    "        x4 = self.down3(x3)  # [B, c4, H/8, W/8]\n",
    "        x5 = self.down4(x4)  # [B, c5, H/16, W/16]\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x,  x3)\n",
    "        x = self.up3(x,  x2)\n",
    "        x = self.up4(x,  x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def convert_to_deploy(self):\n",
    "        \"\"\"Fuse all RepGhost modules in-place for faster inference.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, DoubleRG):\n",
    "                m.convert_to_deploy()\n",
    "            elif isinstance(m, Down) or isinstance(m, Up):\n",
    "                m.convert_to_deploy()\n",
    "            elif isinstance(m, RGBlock):\n",
    "                m.convert_to_deploy()\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Quick sanity test\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    model = RepGhostUNet(n_channels=3, n_classes=1, base_ch=32, use_se=False, bilinear=False)\n",
    "    x = torch.randn(1, 3, 256, 256)\n",
    "    y = model(x)\n",
    "    print(\"out:\", y.shape)  # -> [1, 1, 256, 256]\n",
    "\n",
    "    # Convert to deploy (after training + eval)\n",
    "    model.eval()\n",
    "    model.convert_to_deploy()\n",
    "    with torch.no_grad():\n",
    "        y2 = model(x)\n",
    "    print(\"deploy out:\", y2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0d1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Profiling: GFLOPs, Memory, Parameters, and Inference Time\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total and trainable parameters.\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "def get_model_size_mb(model):\n",
    "    \"\"\"Calculate model size in MB.\"\"\"\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_mb\n",
    "\n",
    "def calculate_flops(model, input_shape=(1, 3, 256, 256), device='cpu'):\n",
    "    \"\"\"\n",
    "    Calculate FLOPs for the model using hook-based method.\n",
    "    Returns GFLOPs (Giga FLOPs).\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    flops_dict = {}\n",
    "    \n",
    "    def conv_hook(module, input, output):\n",
    "        batch_size = input[0].size(0)\n",
    "        output_height, output_width = output.size(2), output.size(3)\n",
    "        \n",
    "        kernel_height, kernel_width = module.kernel_size\n",
    "        in_channels = module.in_channels\n",
    "        out_channels = module.out_channels\n",
    "        groups = module.groups\n",
    "        \n",
    "        # FLOPs = batch_size √ó output_spatial √ó (kernel_ops √ó in_channels / groups) √ó out_channels\n",
    "        # kernel_ops = kernel_h √ó kernel_w\n",
    "        # For bias, add output_height √ó output_width √ó out_channels\n",
    "        \n",
    "        conv_flops = batch_size * output_height * output_width * \\\n",
    "                     (kernel_height * kernel_width * in_channels // groups) * out_channels\n",
    "        \n",
    "        if module.bias is not None:\n",
    "            conv_flops += batch_size * output_height * output_width * out_channels\n",
    "        \n",
    "        flops_dict[id(module)] = conv_flops\n",
    "    \n",
    "    def bn_hook(module, input, output):\n",
    "        batch_size = input[0].size(0)\n",
    "        flops = input[0].numel() * 2  # mean and variance\n",
    "        flops_dict[id(module)] = flops\n",
    "    \n",
    "    def relu_hook(module, input, output):\n",
    "        flops = input[0].numel()\n",
    "        flops_dict[id(module)] = flops\n",
    "    \n",
    "    def linear_hook(module, input, output):\n",
    "        batch_size = input[0].size(0)\n",
    "        weight_ops = module.weight.numel()\n",
    "        flops = batch_size * weight_ops\n",
    "        if module.bias is not None:\n",
    "            flops += batch_size * module.out_features\n",
    "        flops_dict[id(module)] = flops\n",
    "    \n",
    "    hooks = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d):\n",
    "            hooks.append(module.register_forward_hook(conv_hook))\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            hooks.append(module.register_forward_hook(bn_hook))\n",
    "        elif isinstance(module, nn.ReLU):\n",
    "            hooks.append(module.register_forward_hook(relu_hook))\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            hooks.append(module.register_forward_hook(linear_hook))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dummy_input = torch.randn(input_shape).to(device)\n",
    "        _ = model(dummy_input)\n",
    "    \n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    total_flops = sum(flops_dict.values())\n",
    "    gflops = total_flops / 1e9\n",
    "    \n",
    "    return gflops\n",
    "\n",
    "def measure_inference_time(model, input_shape=(1, 3, 256, 256), device='cpu', warmup=10, iterations=100):\n",
    "    \"\"\"\n",
    "    Measure average inference time with warmup.\n",
    "    Returns time in milliseconds.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    \n",
    "    # Warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    # Measure\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    times = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(iterations):\n",
    "            start = time.time()\n",
    "            _ = model(dummy_input)\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            times.append(end - start)\n",
    "    \n",
    "    avg_time = np.mean(times) * 1000  # Convert to ms\n",
    "    std_time = np.std(times) * 1000\n",
    "    \n",
    "    return avg_time, std_time\n",
    "\n",
    "def get_activation_memory(model, input_shape=(1, 3, 256, 256), device='cpu'):\n",
    "    \"\"\"\n",
    "    Estimate peak activation memory during forward pass.\n",
    "    Returns memory in MB.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    activation_sizes = []\n",
    "    \n",
    "    def hook(module, input, output):\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            size = output.numel() * output.element_size()\n",
    "            activation_sizes.append(size)\n",
    "        elif isinstance(output, (list, tuple)):\n",
    "            for o in output:\n",
    "                if isinstance(o, torch.Tensor):\n",
    "                    size = o.numel() * o.element_size()\n",
    "                    activation_sizes.append(size)\n",
    "    \n",
    "    hooks = []\n",
    "    for module in model.modules():\n",
    "        hooks.append(module.register_forward_hook(hook))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dummy_input = torch.randn(input_shape).to(device)\n",
    "        _ = model(dummy_input)\n",
    "    \n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "    \n",
    "    # Peak memory (sum of all activations stored)\n",
    "    peak_memory_mb = sum(activation_sizes) / 1024**2\n",
    "    \n",
    "    return peak_memory_mb\n",
    "\n",
    "def profile_model(model, input_shape=(1, 3, 256, 256), device='cpu', verbose=True):\n",
    "    \"\"\"\n",
    "    Comprehensive model profiling.\n",
    "    Returns dictionary with all metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Parameters\n",
    "    total_params, trainable_params = count_parameters(model)\n",
    "    metrics['total_parameters'] = total_params\n",
    "    metrics['trainable_parameters'] = trainable_params\n",
    "    metrics['non_trainable_parameters'] = total_params - trainable_params\n",
    "    \n",
    "    # Model size\n",
    "    metrics['model_size_mb'] = get_model_size_mb(model)\n",
    "    \n",
    "    # GFLOPs\n",
    "    metrics['gflops'] = calculate_flops(model, input_shape, device)\n",
    "    \n",
    "    # Activation memory\n",
    "    metrics['activation_memory_mb'] = get_activation_memory(model, input_shape, device)\n",
    "    \n",
    "    # Total memory (model + activations)\n",
    "    metrics['total_memory_mb'] = metrics['model_size_mb'] + metrics['activation_memory_mb']\n",
    "    \n",
    "    # Inference time\n",
    "    avg_time, std_time = measure_inference_time(model, input_shape, device)\n",
    "    metrics['avg_inference_time_ms'] = avg_time\n",
    "    metrics['std_inference_time_ms'] = std_time\n",
    "    metrics['fps'] = 1000.0 / avg_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\" * 70)\n",
    "        print(\"MODEL PROFILING RESULTS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"\\nüìä Model Architecture: {model.__class__.__name__}\")\n",
    "        print(f\"   Input Shape: {input_shape}\")\n",
    "        print(f\"   Device: {device}\")\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"PARAMETERS:\")\n",
    "        print(f\"   Total Parameters:        {total_params:,}\")\n",
    "        print(f\"   Trainable Parameters:    {trainable_params:,}\")\n",
    "        print(f\"   Non-trainable Parameters: {total_params - trainable_params:,}\")\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"MEMORY:\")\n",
    "        print(f\"   Model Size:              {metrics['model_size_mb']:.2f} MB\")\n",
    "        print(f\"   Activation Memory:       {metrics['activation_memory_mb']:.2f} MB\")\n",
    "        print(f\"   Total Memory:            {metrics['total_memory_mb']:.2f} MB\")\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"COMPUTE:\")\n",
    "        print(f\"   GFLOPs:                  {metrics['gflops']:.3f}\")\n",
    "        print(f\"   Avg Inference Time:      {avg_time:.2f} ¬± {std_time:.2f} ms\")\n",
    "        print(f\"   Throughput (FPS):        {metrics['fps']:.1f}\")\n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbeb2d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç PROFILING TRAINING MODEL (Before convert_to_deploy)\n",
      "======================================================================\n",
      "MODEL PROFILING RESULTS\n",
      "======================================================================\n",
      "\n",
      "üìä Model Architecture: RepGhostUNet\n",
      "   Input Shape: (1, 3, 256, 256)\n",
      "   Device: cpu\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PARAMETERS:\n",
      "   Total Parameters:        1,591,537\n",
      "   Trainable Parameters:    1,591,537\n",
      "   Non-trainable Parameters: 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MEMORY:\n",
      "   Model Size:              6.17 MB\n",
      "   Activation Memory:       1002.25 MB\n",
      "   Total Memory:            1008.42 MB\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "COMPUTE:\n",
      "   GFLOPs:                  3.806\n",
      "   Avg Inference Time:      55.67 ¬± 7.57 ms\n",
      "   Throughput (FPS):        18.0\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üöÄ PROFILING DEPLOYED MODEL (After convert_to_deploy)\n",
      "======================================================================\n",
      "MODEL PROFILING RESULTS\n",
      "======================================================================\n",
      "\n",
      "üìä Model Architecture: RepGhostUNet\n",
      "   Input Shape: (1, 3, 256, 256)\n",
      "   Device: cpu\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PARAMETERS:\n",
      "   Total Parameters:        1,591,537\n",
      "   Trainable Parameters:    1,591,537\n",
      "   Non-trainable Parameters: 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MEMORY:\n",
      "   Model Size:              6.17 MB\n",
      "   Activation Memory:       1002.25 MB\n",
      "   Total Memory:            1008.42 MB\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "COMPUTE:\n",
      "   GFLOPs:                  3.806\n",
      "   Avg Inference Time:      55.67 ¬± 7.57 ms\n",
      "   Throughput (FPS):        18.0\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üöÄ PROFILING DEPLOYED MODEL (After convert_to_deploy)\n",
      "======================================================================\n",
      "MODEL PROFILING RESULTS\n",
      "======================================================================\n",
      "\n",
      "üìä Model Architecture: RepGhostUNet\n",
      "   Input Shape: (1, 3, 256, 256)\n",
      "   Device: cpu\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PARAMETERS:\n",
      "   Total Parameters:        1,578,289\n",
      "   Trainable Parameters:    1,578,289\n",
      "   Non-trainable Parameters: 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MEMORY:\n",
      "   Model Size:              6.05 MB\n",
      "   Activation Memory:       819.25 MB\n",
      "   Total Memory:            825.30 MB\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "COMPUTE:\n",
      "   GFLOPs:                  3.734\n",
      "   Avg Inference Time:      41.12 ¬± 5.53 ms\n",
      "   Throughput (FPS):        24.3\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üìà COMPARISON: Training vs Deployed\n",
      "======================================================================\n",
      "Parameter Reduction:     1,591,537 ‚Üí 1,578,289\n",
      "Model Size Reduction:    6.17 MB ‚Üí 6.05 MB\n",
      "GFLOPs Reduction:        3.806 ‚Üí 3.734\n",
      "Inference Time Speedup:  55.67 ms ‚Üí 41.12 ms\n",
      "Speedup Factor:          1.35x\n",
      "======================================================================\n",
      "======================================================================\n",
      "MODEL PROFILING RESULTS\n",
      "======================================================================\n",
      "\n",
      "üìä Model Architecture: RepGhostUNet\n",
      "   Input Shape: (1, 3, 256, 256)\n",
      "   Device: cpu\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "PARAMETERS:\n",
      "   Total Parameters:        1,578,289\n",
      "   Trainable Parameters:    1,578,289\n",
      "   Non-trainable Parameters: 0\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MEMORY:\n",
      "   Model Size:              6.05 MB\n",
      "   Activation Memory:       819.25 MB\n",
      "   Total Memory:            825.30 MB\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "COMPUTE:\n",
      "   GFLOPs:                  3.734\n",
      "   Avg Inference Time:      41.12 ¬± 5.53 ms\n",
      "   Throughput (FPS):        24.3\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üìà COMPARISON: Training vs Deployed\n",
      "======================================================================\n",
      "Parameter Reduction:     1,591,537 ‚Üí 1,578,289\n",
      "Model Size Reduction:    6.17 MB ‚Üí 6.05 MB\n",
      "GFLOPs Reduction:        3.806 ‚Üí 3.734\n",
      "Inference Time Speedup:  55.67 ms ‚Üí 41.12 ms\n",
      "Speedup Factor:          1.35x\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example Usage: Profile RepGhostUNet model\n",
    "\n",
    "# Create model\n",
    "model = RepGhostUNet(n_channels=3, n_classes=1, base_ch=32, use_se=False, bilinear=False)\n",
    "\n",
    "# Profile the model (training mode - before deployment)\n",
    "print(\"\\nüîç PROFILING TRAINING MODEL (Before convert_to_deploy)\")\n",
    "metrics_train = profile_model(model, input_shape=(1, 3, 256, 256), device='cpu', verbose=True)\n",
    "\n",
    "# Convert to deployment mode\n",
    "model.eval()\n",
    "model.convert_to_deploy()\n",
    "\n",
    "# Profile the deployed model\n",
    "print(\"\\n\\nüöÄ PROFILING DEPLOYED MODEL (After convert_to_deploy)\")\n",
    "metrics_deploy = profile_model(model, input_shape=(1, 3, 256, 256), device='cpu', verbose=True)\n",
    "\n",
    "# Compare training vs deployed\n",
    "print(\"\\n\\nüìà COMPARISON: Training vs Deployed\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Parameter Reduction:     {metrics_train['total_parameters']:,} ‚Üí {metrics_deploy['total_parameters']:,}\")\n",
    "print(f\"Model Size Reduction:    {metrics_train['model_size_mb']:.2f} MB ‚Üí {metrics_deploy['model_size_mb']:.2f} MB\")\n",
    "print(f\"GFLOPs Reduction:        {metrics_train['gflops']:.3f} ‚Üí {metrics_deploy['gflops']:.3f}\")\n",
    "print(f\"Inference Time Speedup:  {metrics_train['avg_inference_time_ms']:.2f} ms ‚Üí {metrics_deploy['avg_inference_time_ms']:.2f} ms\")\n",
    "speedup = metrics_train['avg_inference_time_ms'] / metrics_deploy['avg_inference_time_ms']\n",
    "print(f\"Speedup Factor:          {speedup:.2f}x\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fd749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä COMPARING DIFFERENT MODEL CONFIGURATIONS\n",
      "====================================================================================================\n",
      "Configuration                  Params (M)      GFLOPs       Memory (MB)     Time (ms)    FPS       \n",
      "====================================================================================================\n",
      "Tiny (16 ch, no SE)            0.41            1.056        503.01          26.65        37.5      \n",
      "Tiny (16 ch, no SE)            0.41            1.056        503.01          26.65        37.5      \n",
      "Small (32 ch, no SE)           1.59            3.806        1008.42         52.49        19.1      \n",
      "Small (32 ch, no SE)           1.59            3.806        1008.42         52.49        19.1      \n",
      "Small (32 ch, with SE)         1.62            3.806        1008.57         59.70        16.7      \n",
      "Small (32 ch, with SE)         1.62            3.806        1008.57         59.70        16.7      \n",
      "Medium (64 ch, no SE)          6.23            14.390       2027.98         106.02       9.4       \n",
      "Medium (64 ch, no SE)          6.23            14.390       2027.98         106.02       9.4       \n",
      "Medium (64 ch, with SE)        6.35            14.390       2028.47         114.98       8.7       \n",
      "====================================================================================================\n",
      "Medium (64 ch, with SE)        6.35            14.390       2028.47         114.98       8.7       \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Optional: Profile different model configurations\n",
    "\n",
    "configs = [\n",
    "    {'base_ch': 16, 'use_se': False, 'name': 'Tiny (16 ch, no SE)'},\n",
    "    {'base_ch': 32, 'use_se': False, 'name': 'Small (32 ch, no SE)'},\n",
    "    {'base_ch': 32, 'use_se': True, 'name': 'Small (32 ch, with SE)'},\n",
    "    {'base_ch': 64, 'use_se': False, 'name': 'Medium (64 ch, no SE)'},\n",
    "    {'base_ch': 64, 'use_se': True, 'name': 'Medium (64 ch, with SE)'},\n",
    "]\n",
    "\n",
    "print(\"\\nüìä COMPARING DIFFERENT MODEL CONFIGURATIONS\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Configuration':<30} {'Params (M)':<15} {'GFLOPs':<12} {'Memory (MB)':<15} {'Time (ms)':<12} {'FPS':<10}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for config in configs:\n",
    "    model = RepGhostUNet(n_channels=3, n_classes=1, \n",
    "                         base_ch=config['base_ch'], \n",
    "                         use_se=config['use_se'], \n",
    "                         bilinear=False)\n",
    "    \n",
    "    metrics = profile_model(model, input_shape=(1, 3, 256, 256), device='cpu', verbose=False)\n",
    "    \n",
    "    params_m = metrics['total_parameters'] / 1e6\n",
    "    print(f\"{config['name']:<30} {params_m:<15.2f} {metrics['gflops']:<12.3f} \"\n",
    "          f\"{metrics['total_memory_mb']:<15.2f} {metrics['avg_inference_time_ms']:<12.2f} \"\n",
    "          f\"{metrics['fps']:<10.1f}\")\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1f988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run once)\n",
    "# !pip install thop torchinfo fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dccc11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Profiling using Popular Libraries\n",
    "from thop import profile, clever_format\n",
    "from torchinfo import summary\n",
    "import torch\n",
    "\n",
    "def profile_with_thop(model, input_shape=(1, 3, 256, 256)):\n",
    "    \"\"\"Profile model using THOP library.\"\"\"\n",
    "    model.eval()\n",
    "    dummy_input = torch.randn(input_shape)\n",
    "    \n",
    "    # Calculate FLOPs and parameters\n",
    "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "    macs, params = clever_format([macs, params], \"%.3f\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"THOP PROFILING\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"MACs (Multiply-Accumulate Operations): {macs}\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Note: FLOPs ‚âà 2 √ó MACs\")\n",
    "    \n",
    "    return macs, params\n",
    "\n",
    "def profile_with_torchinfo(model, input_shape=(1, 3, 256, 256), device='cpu'):\n",
    "    \"\"\"Profile model using torchinfo library.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"TORCHINFO SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    model_stats = summary(\n",
    "        model,\n",
    "        input_size=input_shape,\n",
    "        device=device,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    "        row_settings=[\"var_names\"],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(model_stats)\n",
    "    return model_stats\n",
    "\n",
    "def profile_with_fvcore(model, input_shape=(1, 3, 256, 256)):\n",
    "    \"\"\"Profile model using fvcore library (optional - more detailed).\"\"\"\n",
    "    try:\n",
    "        from fvcore.nn import FlopCountAnalysis, parameter_count\n",
    "        \n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(input_shape)\n",
    "        \n",
    "        flops = FlopCountAnalysis(model, dummy_input)\n",
    "        params = parameter_count(model)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FVCORE PROFILING\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Total FLOPs: {flops.total():,}\")\n",
    "        print(f\"Total FLOPs (GFLOPs): {flops.total() / 1e9:.3f}\")\n",
    "        print(f\"Total Parameters: {params['']:,}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        return flops.total(), params['']\n",
    "    except ImportError:\n",
    "        print(\"\\nfvcore not installed. Install with: pip install fvcore\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1f0a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç PROFILING TRAINING MODEL (Before convert_to_deploy)\n",
      "\n",
      "\n",
      "1Ô∏è‚É£ Using THOP:\n",
      "======================================================================\n",
      "THOP PROFILING\n",
      "======================================================================\n",
      "MACs (Multiply-Accumulate Operations): 3.898G\n",
      "Parameters: 1.592M\n",
      "======================================================================\n",
      "Note: FLOPs ‚âà 2 √ó MACs\n",
      "\n",
      "2Ô∏è‚É£ Using Torchinfo:\n",
      "\n",
      "======================================================================\n",
      "TORCHINFO SUMMARY\n",
      "======================================================================\n",
      "=================================================================================================================================================\n",
      "Layer (type (var_name))                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
      "=================================================================================================================================================\n",
      "RepGhostUNet (RepGhostUNet)                   [1, 3, 256, 256]          [1, 1, 256, 256]          --                        --\n",
      "‚îú‚îÄDoubleRG (inc)                              [1, 3, 256, 256]          [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄRGBlock (b1)                           [1, 3, 256, 256]          [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj1)                [1, 3, 256, 256]          [1, 16, 256, 256]         80                        3,145,760\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg1)              [1, 16, 256, 256]         [1, 16, 256, 256]         208                       9,437,248\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity (se)                     [1, 16, 256, 256]         [1, 16, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj2)                [1, 16, 256, 256]         [1, 32, 256, 256]         576                       33,554,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg2)              [1, 32, 256, 256]         [1, 32, 256, 256]         416                       18,874,496\n",
      "‚îÇ    ‚îî‚îÄRGBlock (b2)                           [1, 32, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj1)                [1, 32, 256, 256]         [1, 16, 256, 256]         544                       33,554,464\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg1)              [1, 16, 256, 256]         [1, 16, 256, 256]         208                       9,437,248\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity (se)                     [1, 16, 256, 256]         [1, 16, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj2)                [1, 16, 256, 256]         [1, 32, 256, 256]         576                       33,554,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg2)              [1, 32, 256, 256]         [1, 32, 256, 256]         416                       18,874,496\n",
      "‚îú‚îÄDown (down1)                                [1, 32, 256, 256]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 32, 256, 256]         [1, 32, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 32, 128, 128]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 32, 128, 128]         [1, 64, 128, 128]         4,512                     64,488,000\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 64, 128, 128]         [1, 64, 128, 128]         5,536                     81,265,216\n",
      "‚îú‚îÄDown (down2)                                [1, 64, 128, 128]         [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 64, 128, 128]         [1, 64, 64, 64]           --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 64, 64, 64]           [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 64, 64, 64]           [1, 128, 64, 64]          15,168                    57,410,688\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 128, 64, 64]          [1, 128, 64, 64]          19,264                    74,187,904\n",
      "‚îú‚îÄDown (down3)                                [1, 128, 64, 64]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 128, 64, 64]          [1, 128, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 128, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 128, 32, 32]          [1, 256, 32, 32]          54,912                    53,872,896\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 256, 32, 32]          [1, 256, 32, 32]          71,296                    70,650,112\n",
      "‚îú‚îÄDown (down4)                                [1, 256, 32, 32]          [1, 512, 16, 16]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 256, 32, 32]          [1, 256, 16, 16]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 256, 16, 16]          [1, 512, 16, 16]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 256, 16, 16]          [1, 512, 16, 16]          208,128                   52,105,728\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 512, 16, 16]          [1, 512, 16, 16]          273,664                   68,882,944\n",
      "‚îú‚îÄUp (up1)                                    [1, 512, 16, 16]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 512, 16, 16]          [1, 256, 32, 32]          524,544                   537,133,056\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 512, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 512, 32, 32]          [1, 256, 32, 32]          104,064                   104,204,544\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 256, 32, 32]          [1, 256, 32, 32]          71,296                    70,650,112\n",
      "‚îú‚îÄUp (up2)                                    [1, 256, 32, 32]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 256, 32, 32]          [1, 128, 64, 64]          131,200                   537,395,200\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 256, 64, 64]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 256, 64, 64]          [1, 128, 64, 64]          27,456                    107,742,336\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 128, 64, 64]          [1, 128, 64, 64]          19,264                    74,187,904\n",
      "‚îú‚îÄUp (up3)                                    [1, 128, 64, 64]          [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 128, 64, 64]          [1, 64, 128, 128]         32,832                    537,919,488\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 128, 128, 128]        [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 128, 128, 128]        [1, 64, 128, 128]         7,584                     114,819,648\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 64, 128, 128]         [1, 64, 128, 128]         5,536                     81,265,216\n",
      "‚îú‚îÄUp (up4)                                    [1, 64, 128, 128]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 64, 128, 128]         [1, 32, 256, 256]         8,224                     538,968,064\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 32, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 64, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 64, 256, 256]         [1, 32, 256, 256]         2,256                     128,975,136\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 32, 256, 256]         [1, 32, 256, 256]         1,744                     95,420,704\n",
      "‚îú‚îÄConv2d (outc)                               [1, 32, 256, 256]         [1, 1, 256, 256]          33                        2,162,688\n",
      "=================================================================================================================================================\n",
      "Total params: 1,591,537\n",
      "Trainable params: 1,591,537\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 3.61\n",
      "=================================================================================================================================================\n",
      "Input size (MB): 0.79\n",
      "Forward/backward pass size (MB): 991.43\n",
      "Params size (MB): 6.37\n",
      "Estimated Total Size (MB): 998.58\n",
      "=================================================================================================================================================\n",
      "\n",
      "3Ô∏è‚É£ Using FVCore:\n",
      "\n",
      "======================================================================\n",
      "FVCORE PROFILING\n",
      "======================================================================\n",
      "=================================================================================================================================================\n",
      "Layer (type (var_name))                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
      "=================================================================================================================================================\n",
      "RepGhostUNet (RepGhostUNet)                   [1, 3, 256, 256]          [1, 1, 256, 256]          --                        --\n",
      "‚îú‚îÄDoubleRG (inc)                              [1, 3, 256, 256]          [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄRGBlock (b1)                           [1, 3, 256, 256]          [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj1)                [1, 3, 256, 256]          [1, 16, 256, 256]         80                        3,145,760\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg1)              [1, 16, 256, 256]         [1, 16, 256, 256]         208                       9,437,248\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity (se)                     [1, 16, 256, 256]         [1, 16, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj2)                [1, 16, 256, 256]         [1, 32, 256, 256]         576                       33,554,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg2)              [1, 32, 256, 256]         [1, 32, 256, 256]         416                       18,874,496\n",
      "‚îÇ    ‚îî‚îÄRGBlock (b2)                           [1, 32, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj1)                [1, 32, 256, 256]         [1, 16, 256, 256]         544                       33,554,464\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg1)              [1, 16, 256, 256]         [1, 16, 256, 256]         208                       9,437,248\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity (se)                     [1, 16, 256, 256]         [1, 16, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj2)                [1, 16, 256, 256]         [1, 32, 256, 256]         576                       33,554,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg2)              [1, 32, 256, 256]         [1, 32, 256, 256]         416                       18,874,496\n",
      "‚îú‚îÄDown (down1)                                [1, 32, 256, 256]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 32, 256, 256]         [1, 32, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 32, 128, 128]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 32, 128, 128]         [1, 64, 128, 128]         4,512                     64,488,000\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 64, 128, 128]         [1, 64, 128, 128]         5,536                     81,265,216\n",
      "‚îú‚îÄDown (down2)                                [1, 64, 128, 128]         [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 64, 128, 128]         [1, 64, 64, 64]           --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 64, 64, 64]           [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 64, 64, 64]           [1, 128, 64, 64]          15,168                    57,410,688\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 128, 64, 64]          [1, 128, 64, 64]          19,264                    74,187,904\n",
      "‚îú‚îÄDown (down3)                                [1, 128, 64, 64]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 128, 64, 64]          [1, 128, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 128, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 128, 32, 32]          [1, 256, 32, 32]          54,912                    53,872,896\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 256, 32, 32]          [1, 256, 32, 32]          71,296                    70,650,112\n",
      "‚îú‚îÄDown (down4)                                [1, 256, 32, 32]          [1, 512, 16, 16]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 256, 32, 32]          [1, 256, 16, 16]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 256, 16, 16]          [1, 512, 16, 16]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 256, 16, 16]          [1, 512, 16, 16]          208,128                   52,105,728\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 512, 16, 16]          [1, 512, 16, 16]          273,664                   68,882,944\n",
      "‚îú‚îÄUp (up1)                                    [1, 512, 16, 16]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 512, 16, 16]          [1, 256, 32, 32]          524,544                   537,133,056\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 512, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 512, 32, 32]          [1, 256, 32, 32]          104,064                   104,204,544\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 256, 32, 32]          [1, 256, 32, 32]          71,296                    70,650,112\n",
      "‚îú‚îÄUp (up2)                                    [1, 256, 32, 32]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 256, 32, 32]          [1, 128, 64, 64]          131,200                   537,395,200\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 256, 64, 64]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 256, 64, 64]          [1, 128, 64, 64]          27,456                    107,742,336\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 128, 64, 64]          [1, 128, 64, 64]          19,264                    74,187,904\n",
      "‚îú‚îÄUp (up3)                                    [1, 128, 64, 64]          [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 128, 64, 64]          [1, 64, 128, 128]         32,832                    537,919,488\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 128, 128, 128]        [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 128, 128, 128]        [1, 64, 128, 128]         7,584                     114,819,648\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 64, 128, 128]         [1, 64, 128, 128]         5,536                     81,265,216\n",
      "‚îú‚îÄUp (up4)                                    [1, 64, 128, 128]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 64, 128, 128]         [1, 32, 256, 256]         8,224                     538,968,064\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 32, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 64, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 64, 256, 256]         [1, 32, 256, 256]         2,256                     128,975,136\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 32, 256, 256]         [1, 32, 256, 256]         1,744                     95,420,704\n",
      "‚îú‚îÄConv2d (outc)                               [1, 32, 256, 256]         [1, 1, 256, 256]          33                        2,162,688\n",
      "=================================================================================================================================================\n",
      "Total params: 1,591,537\n",
      "Trainable params: 1,591,537\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 3.61\n",
      "=================================================================================================================================================\n",
      "Input size (MB): 0.79\n",
      "Forward/backward pass size (MB): 991.43\n",
      "Params size (MB): 6.37\n",
      "Estimated Total Size (MB): 998.58\n",
      "=================================================================================================================================================\n",
      "\n",
      "3Ô∏è‚É£ Using FVCore:\n",
      "\n",
      "======================================================================\n",
      "FVCORE PROFILING\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add encountered 45 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 4 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 4 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 2,143,420,416\n",
      "Total FLOPs (GFLOPs): 2.143\n",
      "Total Parameters: 1,591,537\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üöÄ PROFILING DEPLOYED MODEL (After convert_to_deploy)\n",
      "\n",
      "\n",
      "1Ô∏è‚É£ Using THOP (Deployed):\n",
      "======================================================================\n",
      "THOP PROFILING\n",
      "======================================================================\n",
      "MACs (Multiply-Accumulate Operations): 3.706G\n",
      "Parameters: 1.578M\n",
      "======================================================================\n",
      "Note: FLOPs ‚âà 2 √ó MACs\n",
      "\n",
      "2Ô∏è‚É£ Using Torchinfo (Deployed):\n",
      "\n",
      "======================================================================\n",
      "TORCHINFO SUMMARY\n",
      "======================================================================\n",
      "=================================================================================================================================================\n",
      "Layer (type (var_name))                       Input Shape               Output Shape              Param #                   Mult-Adds\n",
      "=================================================================================================================================================\n",
      "RepGhostUNet (RepGhostUNet)                   [1, 3, 256, 256]          [1, 1, 256, 256]          --                        --\n",
      "‚îú‚îÄDoubleRG (inc)                              [1, 3, 256, 256]          [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄRGBlock (b1)                           [1, 3, 256, 256]          [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj1)                [1, 3, 256, 256]          [1, 16, 256, 256]         80                        3,145,760\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg1)              [1, 16, 256, 256]         [1, 16, 256, 256]         160                       10,485,760\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity (se)                     [1, 16, 256, 256]         [1, 16, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj2)                [1, 16, 256, 256]         [1, 32, 256, 256]         576                       33,554,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg2)              [1, 32, 256, 256]         [1, 32, 256, 256]         320                       20,971,520\n",
      "‚îÇ    ‚îî‚îÄRGBlock (b2)                           [1, 32, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj1)                [1, 32, 256, 256]         [1, 16, 256, 256]         544                       33,554,464\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg1)              [1, 16, 256, 256]         [1, 16, 256, 256]         160                       10,485,760\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄIdentity (se)                     [1, 16, 256, 256]         [1, 16, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄSequential (proj2)                [1, 16, 256, 256]         [1, 32, 256, 256]         576                       33,554,496\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRepGhostModule (rg2)              [1, 32, 256, 256]         [1, 32, 256, 256]         320                       20,971,520\n",
      "‚îú‚îÄDown (down1)                                [1, 32, 256, 256]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 32, 256, 256]         [1, 32, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 32, 128, 128]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 32, 128, 128]         [1, 64, 128, 128]         4,224                     66,060,480\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 64, 128, 128]         [1, 64, 128, 128]         5,248                     82,837,696\n",
      "‚îú‚îÄDown (down2)                                [1, 64, 128, 128]         [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 64, 128, 128]         [1, 64, 64, 64]           --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 64, 64, 64]           [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 64, 64, 64]           [1, 128, 64, 64]          14,592                    58,196,352\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 128, 64, 64]          [1, 128, 64, 64]          18,688                    74,973,568\n",
      "‚îú‚îÄDown (down3)                                [1, 128, 64, 64]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 128, 64, 64]          [1, 128, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 128, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 128, 32, 32]          [1, 256, 32, 32]          53,760                    54,264,576\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 256, 32, 32]          [1, 256, 32, 32]          70,144                    71,041,792\n",
      "‚îú‚îÄDown (down4)                                [1, 256, 32, 32]          [1, 512, 16, 16]          --                        --\n",
      "‚îÇ    ‚îî‚îÄMaxPool2d (pool)                       [1, 256, 32, 32]          [1, 256, 16, 16]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 256, 16, 16]          [1, 512, 16, 16]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 256, 16, 16]          [1, 512, 16, 16]          205,824                   52,299,264\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 512, 16, 16]          [1, 512, 16, 16]          271,360                   69,076,480\n",
      "‚îú‚îÄUp (up1)                                    [1, 512, 16, 16]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 512, 16, 16]          [1, 256, 32, 32]          524,544                   537,133,056\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 256, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 512, 32, 32]          [1, 256, 32, 32]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 512, 32, 32]          [1, 256, 32, 32]          102,912                   104,596,224\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 256, 32, 32]          [1, 256, 32, 32]          70,144                    71,041,792\n",
      "‚îú‚îÄUp (up2)                                    [1, 256, 32, 32]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 256, 32, 32]          [1, 128, 64, 64]          131,200                   537,395,200\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 128, 64, 64]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 256, 64, 64]          [1, 128, 64, 64]          --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 256, 64, 64]          [1, 128, 64, 64]          26,880                    108,528,000\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 128, 64, 64]          [1, 128, 64, 64]          18,688                    74,973,568\n",
      "‚îú‚îÄUp (up3)                                    [1, 128, 64, 64]          [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 128, 64, 64]          [1, 64, 128, 128]         32,832                    537,919,488\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 64, 128, 128]         [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 128, 128, 128]        [1, 64, 128, 128]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 128, 128, 128]        [1, 64, 128, 128]         7,296                     116,392,128\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 64, 128, 128]         [1, 64, 128, 128]         5,248                     82,837,696\n",
      "‚îú‚îÄUp (up4)                                    [1, 64, 128, 128]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄConvTranspose2d (up)                   [1, 64, 128, 128]         [1, 32, 256, 256]         8,224                     538,968,064\n",
      "‚îÇ    ‚îî‚îÄIdentity (reduce)                      [1, 32, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îî‚îÄDoubleRG (block)                       [1, 64, 256, 256]         [1, 32, 256, 256]         --                        --\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b1)                      [1, 64, 256, 256]         [1, 32, 256, 256]         2,112                     132,120,672\n",
      "‚îÇ    ‚îÇ    ‚îî‚îÄRGBlock (b2)                      [1, 32, 256, 256]         [1, 32, 256, 256]         1,600                     98,566,240\n",
      "‚îú‚îÄConv2d (outc)                               [1, 32, 256, 256]         [1, 1, 256, 256]          33                        2,162,688\n",
      "=================================================================================================================================================\n",
      "Total params: 1,578,289\n",
      "Trainable params: 1,578,289\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 3.64\n",
      "=================================================================================================================================================\n",
      "Input size (MB): 0.79\n",
      "Forward/backward pass size (MB): 607.65\n",
      "Params size (MB): 6.31\n",
      "Estimated Total Size (MB): 614.75\n",
      "=================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example: Profile RepGhostUNet using libraries\n",
    "\n",
    "# Create a fresh model\n",
    "model = RepGhostUNet(n_channels=3, n_classes=1, base_ch=32, use_se=False, bilinear=False)\n",
    "\n",
    "print(\"\\nüîç PROFILING TRAINING MODEL (Before convert_to_deploy)\\n\")\n",
    "\n",
    "# Method 1: THOP\n",
    "print(\"\\n1Ô∏è‚É£ Using THOP:\")\n",
    "macs, params = profile_with_thop(model, input_shape=(1, 3, 256, 256))\n",
    "\n",
    "# Method 2: Torchinfo (most detailed)\n",
    "print(\"\\n2Ô∏è‚É£ Using Torchinfo:\")\n",
    "stats = profile_with_torchinfo(model, input_shape=(1, 3, 256, 256))\n",
    "\n",
    "# Method 3: FVCore (optional)\n",
    "print(\"\\n3Ô∏è‚É£ Using FVCore:\")\n",
    "flops, params_fv = profile_with_fvcore(model, input_shape=(1, 3, 256, 256))\n",
    "\n",
    "# Now test deployed model\n",
    "print(\"\\n\\nüöÄ PROFILING DEPLOYED MODEL (After convert_to_deploy)\\n\")\n",
    "model.eval()\n",
    "model.convert_to_deploy()\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Using THOP (Deployed):\")\n",
    "macs_deploy, params_deploy = profile_with_thop(model, input_shape=(1, 3, 256, 256))\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Using Torchinfo (Deployed):\")\n",
    "stats_deploy = profile_with_torchinfo(model, input_shape=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0aced",
   "metadata": {},
   "source": [
    "## üìö Library Comparison\n",
    "\n",
    "### **THOP (Recommended for simplicity)**\n",
    "- ‚úÖ Easy to use\n",
    "- ‚úÖ Gives MACs and parameters in human-readable format\n",
    "- ‚úÖ Lightweight\n",
    "- ‚ùå Less detailed breakdown\n",
    "\n",
    "### **Torchinfo (Recommended for detailed analysis)**\n",
    "- ‚úÖ Very detailed layer-by-layer breakdown\n",
    "- ‚úÖ Shows input/output shapes\n",
    "- ‚úÖ Shows memory usage per layer\n",
    "- ‚úÖ Beautiful formatting\n",
    "- ‚úÖ Can export to different formats\n",
    "\n",
    "### **FVCore (Facebook Research)**\n",
    "- ‚úÖ Very accurate FLOPs counting\n",
    "- ‚úÖ Used in official PyTorch repositories\n",
    "- ‚úÖ Can provide per-operation breakdown\n",
    "- ‚ùå Slightly more complex API\n",
    "\n",
    "### **Quick Start:**\n",
    "```python\n",
    "# Install (uncomment the first cell above and run it)\n",
    "# pip install thop torchinfo fvcore\n",
    "\n",
    "# Then just run the example cells!\n",
    "```\n",
    "\n",
    "### Note on MACs vs FLOPs:\n",
    "- **MACs** (Multiply-Accumulate Operations): One multiply + one add\n",
    "- **FLOPs** (Floating Point Operations): Individual operations\n",
    "- **Relationship**: FLOPs ‚âà 2 √ó MACs (approximately)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repghostunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
